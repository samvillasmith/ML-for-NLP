{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXTu3BG8dggL0ob007LvDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samvillasmith/ML-for-NLP/blob/main/lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "Lemmatization is a process in natural language processing (NLP) that reduces a word to its base or dictionary form, known as a lemma. Unlike stemming, which just chops off the end of a word, lemmatization considers the meaning and context of the word to return its root form. For example, the words \"running,\" \"ran,\" and \"runs\" would all be lemmatized to the lemma \"run.\" This is useful for tasks like text analysis and information retrieval, where you want to treat different forms of the same word as equivalent."
      ],
      "metadata": {
        "id": "a_mjDOAO3Ap7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h3lCE_C27lB",
        "outputId": "96bd71fb-bacb-4efc-b807-97c22addc9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# WordNet Lemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "POS - Noun-n\n",
        "verb-v\n",
        "adj-a\n",
        "adverb-r\n",
        "'''\n",
        "lemmatizer.lemmatize(\"going\", pos=\"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hH47_0pu3rwj",
        "outputId": "5d224706-6cbc-408b-bb93-a1c98a517743"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['eating', 'eats', 'eat', 'ate', 'adjustable', 'rafting', 'ability', 'meeting', 'programming', 'program', 'writing', 'writes', 'writer']\n",
        "\n",
        "for word in words:\n",
        "  print(word + '==>' + lemmatizer.lemmatize(word, pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xW0p9if3uZ6",
        "outputId": "a02fd9a3-6e2d-41f5-91f0-b2c9495234b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating==>eat\n",
            "eats==>eat\n",
            "eat==>eat\n",
            "ate==>eat\n",
            "adjustable==>adjustable\n",
            "rafting==>raft\n",
            "ability==>ability\n",
            "meeting==>meet\n",
            "programming==>program\n",
            "program==>program\n",
            "writing==>write\n",
            "writes==>write\n",
            "writer==>writer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4MV60_qx4kRr",
        "outputId": "c15c9f13-a9fa-4a5e-c082-693613bb006d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}